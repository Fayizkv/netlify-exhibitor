# Live Transcription System - Complete Flow Explanation

## ğŸ“‹ Table of Contents
1. [System Overview](#system-overview)
2. [Architecture Components](#architecture-components)
3. [Data Flow](#data-flow)
4. [Language Switching Mechanism](#language-switching-mechanism)
5. [Dual Socket System](#dual-socket-system)
6. [Provider Selection Logic](#provider-selection-logic)
7. [Translation Pipeline](#translation-pipeline)
8. [User Experience During Language Switch](#user-experience-during-language-switch)

---

## ğŸ¯ System Overview

The Live Transcription System is a real-time audio streaming and transcription service that:
- Captures audio from user's microphone
- Streams audio to transcription providers (Deepgram Nova or Speechmatics)
- Broadcasts live transcriptions to viewers via Socket.IO
- Translates transcriptions to multiple target languages in real-time
- Supports dynamic language switching without interrupting the audio stream

### Key Features
âœ… Real-time audio transcription  
âœ… Multi-language support (60+ languages)  
âœ… Dual provider system (Deepgram Nova + Speechmatics)  
âœ… Live translation to 4 target languages  
âœ… Seamless language switching during live sessions  
âœ… Broadcasting to unlimited viewers  

---

## ğŸ—ï¸ Architecture Components

### 1. **Main Component** (`index.jsx`)
The orchestration layer that manages UI and coordinates all services.

```javascript
// Key State Variables
const [selectedLanguage, setSelectedLanguage] = useState(null);
const [isRecording, setIsRecording] = useState(false);
const [socket, setSocket] = useState(null); // Main transcription socket
const [geminiTranslationSocket, setGeminiTranslationSocket] = useState(null); // Translation socket
```

**Responsibilities:**
- Manage socket connections (2 sockets)
- Handle user interactions (start/stop recording, language selection)
- Initialize transcription hook with proper parameters
- Display transcription results in UI
- Show loading states during language switches

---

### 2. **Transcription Hook** (`useTranscriptionService.js`)
The business logic layer that manages transcription lifecycle.

```javascript
const useTranscriptionService = (
  targetLanguage,      // Selected language code (e.g., 'en-US', 'es', 'hi')
  roomId,              // Room identifier
  sessionId,           // Session identifier
  socket,              // Main transcription socket
  setSocketConnected,  // Socket status callback
  onRecordingComplete, // Recording completion callback
  translationEnabled,  // Translation feature flag
  translationSocket,   // OLD translation socket (deprecated)
  translationSocketConnected, // OLD socket status
  novaModel,           // Nova model version ('nova-2' or 'nova-3')
  targetLanguages,     // OLD target languages array
  geminiTranslationSocket, // NEW Gemini translation socket
  geminiTranslationSocketConnected, // NEW Gemini socket status
  geminiTargetLanguages, // NEW First 4 target languages
  sessionContext       // NEW Session metadata for better translations
) => {
  // ... hook implementation
};
```

**Responsibilities:**
- Select appropriate transcription provider based on language
- Initialize and manage transcription service (Deepgram or Speechmatics)
- Handle MediaRecorder for audio capture
- Process transcription results (interim and final)
- Broadcast transcriptions to main socket
- Send transcriptions to translation service
- Manage cleanup on language switch or stop

---

### 3. **Transcription Services**

#### **DeepgramService** (`services/DeepgramService.js`)
WebSocket-based service for Deepgram Nova transcription.

```javascript
class DeepgramService {
  async initialize(config) {
    // Initialize WebSocket connection to Deepgram
    // Setup event listeners: onOpen, onTranscript, onError, onClose
  }
  
  sendAudioData(audioBlob) {
    // Stream audio chunks to Deepgram
  }
  
  close() {
    // Close WebSocket connection
  }
}
```

**Supported Languages:** 40+ languages via Nova-2 and Nova-3 models  
**Use Case:** High-quality transcription for well-supported languages

---

#### **SpeechmaticsService** (`services/SpeechmaticsService.js`)
Real-time client service for Speechmatics transcription.

```javascript
class SpeechmaticsService {
  async initialize(config) {
    // Initialize Speechmatics real-time client
    // Setup event listeners: onOpen, onTranscript, onError, onClose
  }
  
  async sendAudioData(audioChunk) {
    // Stream audio chunks to Speechmatics
  }
  
  close() {
    // Stop recognition and close connection
  }
}
```

**Supported Languages:** 60+ languages including rare languages  
**Use Case:** Fallback for languages not supported by Deepgram Nova

---

### 4. **Translation Service** (`services/GeminiTranslationService.js`)
Buffers and sends transcriptions to Gemini translation server.

```javascript
class GeminiTranslationService {
  initialize(socket, sessionId, sourceLanguage, targetLanguages) {
    // Initialize translation socket connection
    // Setup socket event listeners
  }
  
  sendForTranslation(text, isFinal) {
    // Buffer complete sentences
    // Send 2 sentences at a time to translation server
  }
  
  flushBuffer() {
    // Send any remaining sentences in buffer
  }
}
```

**Features:**
- Sentence-level buffering (sends 2 complete sentences at a time)
- Smart sentence detection (supports multiple scripts)
- Session context for better translation quality
- Automatic flushing on stop/language change

---

### 5. **Language Utilities** (`utils/languageUtils.js`)
Helper functions for language management.

```javascript
// Determine which provider supports a language
export const getProviderForLanguage = (code) => {
  if (SUPPORTED_LANGUAGES.find(l => l.code === code)) return 'nova';
  if (SPEECHMATICS_LANGUAGES.find(l => l.code === code)) return 'speechmatics';
  return null;
};

// Get appropriate Nova model for language
export const getNovaModelForLanguage = (code) => {
  const lang = SUPPORTED_LANGUAGES.find(l => l.code === code);
  return lang ? lang.novaSupport : null; // 'nova-2' or 'nova-3'
};

// Check if language is supported by any provider
export const isLanguageSupported = (code) => {
  return getProviderForLanguage(code) !== null;
};
```

---

## ğŸ”„ Data Flow

### Complete Request/Response Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER MICROPHONE AUDIO                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MediaRecorder (Browser API)                       â”‚
â”‚  â€¢ Captures audio in chunks (100ms intervals)                       â”‚
â”‚  â€¢ Stores chunks for recording save                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROVIDER SELECTION (Language-Based)                     â”‚
â”‚  â€¢ Nova (Deepgram): If language in SUPPORTED_LANGUAGES              â”‚
â”‚  â€¢ Speechmatics: If language in SPEECHMATICS_LANGUAGES only         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  DeepgramService        â”‚     â”‚ SpeechmaticsService    â”‚
    â”‚  â€¢ WebSocket Stream     â”‚     â”‚ â€¢ Real-time Client     â”‚
    â”‚  â€¢ Nova-2 / Nova-3      â”‚     â”‚ â€¢ Enhanced Operating   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                               â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    TRANSCRIPTION RESULTS                â”‚
        â”‚  â€¢ Interim: Continuous updates          â”‚
        â”‚  â€¢ Final: Complete sentences            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                   â”‚
        â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SOCKET 1: MAIN     â”‚      â”‚  SOCKET 2: TRANSLATION     â”‚
â”‚ Transcription Server â”‚      â”‚   Gemini Translation       â”‚
â”‚                      â”‚      â”‚                            â”‚
â”‚ â€¢ Broadcasts to      â”‚      â”‚ â€¢ Buffers 2 sentences      â”‚
â”‚   all viewers        â”‚      â”‚ â€¢ Translates to 4 langs    â”‚
â”‚ â€¢ Stores in DB       â”‚      â”‚ â€¢ Broadcasts translations  â”‚
â”‚ â€¢ Real-time updates  â”‚      â”‚ â€¢ Context-aware            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”€ Language Switching Mechanism

### How Language Switching Works Without Interruption

When a user switches language during a live session, here's what happens:

#### **Step 1: User Selects New Language**
```javascript
// In index.jsx
const handleLanguageSelect = (option) => {
  const selected = availableLanguagesForUI.find(lang => lang.code === option.id);
  setSelectedLanguage(selected); // Triggers hook re-execution
  
  if (isRecording) {
    stopTranscription(); // Gracefully stop current transcription
  }
};
```

#### **Step 2: Hook Re-executes with New Language**
```javascript
// useTranscriptionService.js receives new targetLanguage parameter
useEffect(() => {
  // Hook detects language change
  console.log("Language changed to:", targetLanguage);
  
  // Cleanup previous provider connection
  return () => {
    if (deepgramServiceRef.current) {
      deepgramServiceRef.current.close();
    }
    if (speechmaticsServiceRef.current) {
      speechmaticsServiceRef.current.close();
    }
  };
}, [targetLanguage]);
```

#### **Step 3: Provider Selection Based on New Language**
```javascript
const startTranscription = useCallback(async () => {
  // Determine new provider
  const provider = getProviderForLanguage(targetLanguage);
  console.log(`Switching to provider: ${provider} for language: ${targetLanguage}`);
  
  // Initialize new provider
  if (provider === 'nova') {
    const deepgramService = new DeepgramService();
    await deepgramService.initialize({
      apiKey: DEEPGRAM_API_KEY,
      model: getNovaModelForLanguage(targetLanguage),
      language: targetLanguage,
      // ... config
    });
  } else if (provider === 'speechmatics') {
    const speechmaticsService = new SpeechmaticsService();
    await speechmaticsService.initialize({
      apiKey: SPEECHMATICS_API_KEY,
      language: targetLanguage,
      // ... config
    });
  }
  
  // MediaRecorder continues without interruption
  mediaRecorder.start(100);
}, [targetLanguage]);
```

#### **Step 4: Socket Reconnection**
```javascript
// Both sockets remain connected, just updated with new language
// Main socket: Continues broadcasting with new language metadata
socket.emit("transcription", {
  roomId: sessionId,
  text: transcript,
  language: targetLanguage, // NEW LANGUAGE
  isFinal: true,
});

// Translation socket: Updates source language
geminiTranslationService.updateConfig({
  sourceLanguage: targetLanguage, // NEW SOURCE LANGUAGE
  targetLanguages: geminiTargetLanguages,
});
```

### What Happens Behind the Scenes

| Step | Action | User Visible? | Duration |
|------|--------|---------------|----------|
| 1. Stop current provider | Close WebSocket/Client | âš ï¸ Loading indicator | ~100ms |
| 2. Select new provider | Determine based on language | ğŸ”„ Loading indicator | ~50ms |
| 3. Initialize new connection | Connect to provider | ğŸ”„ Loading indicator | ~500-1000ms |
| 4. Start audio streaming | Resume MediaRecorder | âœ… Resume display | ~100ms |
| 5. Update sockets | Emit with new language | âœ… Resume display | ~50ms |
| **Total** | **Full language switch** | **â±ï¸ 1-2 seconds** | **~800-1300ms** |

### User Experience During Switch

```
User Timeline:
â”œâ”€ [T+0s]    User clicks new language dropdown
â”œâ”€ [T+0.1s]  Loading indicator appears
â”œâ”€ [T+0.2s]  Current transcription stops
â”œâ”€ [T+0.3s]  Old provider disconnects
â”œâ”€ [T+0.8s]  New provider connects
â”œâ”€ [T+1.0s]  Transcription resumes in new language
â””â”€ [T+1.2s]  Loading indicator disappears
```

**What User Sees:**
- âœ… Smooth loading indicator
- âœ… Audio continues recording (no audio gap)
- âœ… Previous transcriptions remain visible
- âœ… New transcriptions appear in new language
- âœ… Translation continues to target languages
- âŒ No audio interruption
- âŒ No connection errors
- âŒ No data loss

---

## ğŸ”Œ Dual Socket System

### Socket 1: Main Transcription Socket

**Purpose:** Broadcast live transcriptions to all viewers in the session

**Connection:**
```javascript
// index.jsx
const baseurl = import.meta.env.VITE_LIVE_TRANSCRIPTION_SERVER_URL;
const newSocket = io(baseurl, {
  transports: ["websocket", "polling"],
  timeout: 20000,
});

newSocket.on("connect", () => {
  console.log("Connected to transcription server");
  newSocket.emit("join-room", sessionId); // Join session room
});
```

**Data Flow:**
```javascript
// useTranscriptionService.js - Broadcasting transcriptions
socket.emit("transcription", {
  roomId: sessionId,           // Session identifier
  text: transcriptionText,     // Transcribed text
  timestamp: new Date(),       // Timestamp
  isFinal: true/false,        // Interim or final
  language: targetLanguage,    // Source language
});
```

**Server-side:** Broadcasting to all connected viewers
```javascript
// Server receives and broadcasts to room
io.to(sessionId).emit("transcription-update", {
  text: transcriptionText,
  timestamp: timestamp,
  isFinal: isFinal,
  language: language,
});
```

**Features:**
- âœ… Real-time broadcasting to unlimited viewers
- âœ… Automatic reconnection on network issues
- âœ… Room-based isolation (only session viewers receive updates)
- âœ… Supports both interim and final transcriptions

---

### Socket 2: Gemini Translation Socket

**Purpose:** Translate transcriptions to multiple target languages using Gemini AI

**Connection:**
```javascript
// index.jsx
const geminiServerUrl = import.meta.env.VITE_GEMINI_TRANSLATION_SERVER_URL;
const newGeminiSocket = io(geminiServerUrl, {
  transports: ["websocket", "polling"],
  timeout: 20000,
});

newGeminiSocket.on("connect", () => {
  console.log("Connected to Gemini translation server");
});
```

**Data Flow:**
```javascript
// GeminiTranslationService.js - Sending for translation
geminiTranslationSocket.emit("start-translation", {
  text: twoSentences,              // 2 complete sentences
  sessionId: sessionId,            // Session identifier
  targetLanguages: [               // First 4 target languages
    'hindi', 'malayalam', 'tamil', 'telugu'
  ],
  sessionContext: {                // Metadata for better translation
    sessionTitle: "Keynote Speech",
    sessionType: "Conference",
    eventTitle: "Tech Summit 2025",
    speakers: ["John Doe"],
    // ... additional context
  }
});
```

**Translation Process:**
```javascript
// Server receives translation request
1. Buffer: Accumulate 2 complete sentences
2. Context: Include session metadata
3. Translate: Use Gemini Pro API
4. Broadcast: Send translations to room

// Server emits translations
io.to(sessionId).emit("translation-update", {
  originalText: "Original sentence",
  translations: {
    hindi: "à¤…à¤¨à¥à¤µà¤¾à¤¦à¤¿à¤¤ à¤µà¤¾à¤•à¥à¤¯",
    malayalam: "à´µà´¿à´µàµ¼à´¤àµà´¤à´¨à´‚ à´šàµ†à´¯àµà´¤ à´µà´¾à´šà´•à´‚",
    tamil: "à®®à¯Šà®´à®¿à®ªà¯†à®¯à®°à¯à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿ à®µà®¾à®•à¯à®•à®¿à®¯à®®à¯",
    telugu: "à°…à°¨à±à°µà°¦à°¿à°‚à°šà°¬à°¡à°¿à°¨ à°µà°¾à°•à±à°¯à°‚"
  },
  timestamp: new Date(),
});
```

**Sentence Buffering Logic:**
```javascript
// Why send 2 sentences at a time?
// âœ… Better context for accurate translation
// âœ… Reduces API calls (cost optimization)
// âœ… Improves translation coherence
// âœ… Handles sentence-spanning phrases

Example:
Sentence 1: "The event will start soon."
Sentence 2: "Please take your seats."

Combined translation (better):
"The event will start soon. Please take your seats."
â†’ More coherent translation with context

vs.

Individual translation (worse):
"The event will start soon." â†’ Lacks context
"Please take your seats." â†’ Lacks context
```

**Features:**
- âœ… Sentence-level buffering (2 sentences)
- âœ… Multi-script support (Latin, Devanagari, Arabic, etc.)
- âœ… Context-aware translations (session metadata)
- âœ… Automatic flushing on stop/language change
- âœ… Support for 4 target languages simultaneously
- âœ… Real-time translation updates to viewers

---

## ğŸŒ Provider Selection Logic

### Decision Tree for Provider Selection

```
START: User selects language
    â†“
Is language in SUPPORTED_LANGUAGES?
    â†“â”€ YES â†’ Check Nova model
    â”‚         â†“
    â”‚    Is 'nova-3' supported?
    â”‚         â†“â”€ YES â†’ Use Deepgram Nova-3
    â”‚         â†“â”€ NO  â†’ Use Deepgram Nova-2
    â”‚
    â†“â”€ NO â†’ Is language in SPEECHMATICS_LANGUAGES?
              â†“â”€ YES â†’ Use Speechmatics
              â†“â”€ NO  â†’ Show "Language Not Supported" error
```

### Language Support Matrix

| Language | Provider | Model/Config | Quality |
|----------|----------|--------------|---------|
| English (US) | Deepgram | nova-3 | â­â­â­â­â­ |
| Spanish | Deepgram | nova-3 | â­â­â­â­â­ |
| French | Deepgram | nova-3 | â­â­â­â­â­ |
| German | Deepgram | nova-3 | â­â­â­â­â­ |
| Hindi | Deepgram | nova-2 | â­â­â­â­ |
| Chinese | Deepgram | nova-2 | â­â­â­â­ |
| Korean | Deepgram | nova-2 | â­â­â­â­ |
| Arabic | Speechmatics | enhanced | â­â­â­â­ |
| Malayalam | Speechmatics | enhanced | â­â­â­â­ |
| Esperanto | Speechmatics | enhanced | â­â­â­ |
| Basque | Speechmatics | enhanced | â­â­â­ |

### Provider Comparison

| Feature | Deepgram Nova | Speechmatics |
|---------|---------------|--------------|
| **Supported Languages** | 40+ (Nova-2 & Nova-3) | 60+ |
| **Language Detection** | Manual selection | Manual selection |
| **Interim Results** | âœ… Yes | âœ… Yes |
| **Punctuation** | âœ… Yes (smart format) | âœ… Yes (auto) |
| **Disfluency Removal** | âœ… Yes | âœ… Yes |
| **Latency** | ~200-500ms | ~300-600ms |
| **Quality** | â­â­â­â­â­ | â­â­â­â­ |
| **Cost** | $$ | $$ |
| **Connection Type** | WebSocket | Real-time Client |
| **Offline Mode** | âŒ No | âŒ No |

---

## ğŸ“Š Translation Pipeline

### Complete Translation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRANSCRIPTION RESULT                          â”‚
â”‚  "Welcome to the event. Please take your seats."                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SENTENCE DETECTION & BUFFERING                      â”‚
â”‚  â€¢ Regex-based sentence splitting                               â”‚
â”‚  â€¢ Support for multiple scripts (Latin, Devanagari, Arabic)     â”‚
â”‚  â€¢ Buffer incomplete sentences                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Complete Sentence Buffer  â”‚
                â”‚  ["Welcome to the event.", â”‚
                â”‚   "Please take your seats."]â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    Send when buffer >= 2 sentences
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           EMIT TO GEMINI TRANSLATION SERVER                      â”‚
â”‚  {                                                               â”‚
â”‚    text: "Welcome to the event. Please take your seats.",       â”‚
â”‚    sessionId: "session-123",                                    â”‚
â”‚    targetLanguages: ["hindi", "malayalam", "tamil", "telugu"],  â”‚
â”‚    sessionContext: { ... }                                      â”‚
â”‚  }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GEMINI PRO TRANSLATION ENGINE                       â”‚
â”‚  â€¢ Uses session context for better accuracy                     â”‚
â”‚  â€¢ Translates to 4 languages in parallel                        â”‚
â”‚  â€¢ Preserves formatting and tone                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 TRANSLATION RESULTS                              â”‚
â”‚  {                                                               â”‚
â”‚    hindi: "à¤†à¤¯à¥‹à¤œà¤¨ à¤®à¥‡à¤‚ à¤†à¤ªà¤•à¤¾ à¤¸à¥à¤µà¤¾à¤—à¤¤ à¤¹à¥ˆà¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤ªà¤¨à¥€ à¤¸à¥€à¤Ÿà¥‡à¤‚ à¤²à¥‡à¤‚à¥¤",    â”‚
â”‚    malayalam: "à´ªà´°à´¿à´ªà´¾à´Ÿà´¿à´¯à´¿à´²àµ‡à´•àµà´•àµ à´¸àµà´µà´¾à´—à´¤à´‚. à´¨à´¿à´™àµà´™à´³àµà´Ÿàµ† à´‡à´°à´¿à´ªàµà´ªà´¿à´Ÿà´™àµà´™àµ¾...", â”‚
â”‚    tamil: "à®¨à®¿à®•à®´à¯à®µà¯à®•à¯à®•à¯ à®µà®°à®µà¯‡à®±à¯à®•à®¿à®±à¯‹à®®à¯. à®¤à®¯à®µà¯à®šà¯†à®¯à¯à®¤à¯ à®‰à®™à¯à®•à®³à¯ à®‡à®°à¯à®•à¯à®•à¯ˆà®•à®³à¯ˆ...", â”‚
â”‚    telugu: "à°ˆà°µà±†à°‚à°Ÿà±â€Œà°•à± à°¸à±à°µà°¾à°—à°¤à°‚. à°¦à°¯à°šà±‡à°¸à°¿ à°®à±€ à°¸à±€à°Ÿà±à°²à± à°¤à±€à°¸à±à°•à±‹à°‚à°¡à°¿."      â”‚
â”‚  }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           BROADCAST TO SESSION VIEWERS                           â”‚
â”‚  io.to(sessionId).emit("translation-update", translations)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Sentence Detection Regex

```javascript
// Supports multiple scripts and punctuation marks
const sentenceEndRegex = /(?:[.!?â€¦]|[\u0964\u0965\u06D4\u061F])+(?:["''")\]]*\s+|$)/g;

// Breakdown:
// [.!?â€¦]           - Common sentence endings
// \u0964           - Devanagari danda (à¥¤) - Hindi, Sanskrit, etc.
// \u0965           - Devanagari double danda (à¥¥)
// \u06D4           - Arabic full stop (Û”) - Urdu, Persian, etc.
// \u061F           - Arabic question mark (ØŸ)
// ["''")\]]*       - Optional closing quotes/brackets
// \s+              - Whitespace after punctuation
// |$               - Or end of string
```

**Example Sentence Detection:**
```javascript
Input: "Welcome to the event. Please take your seats. Thank you."

Output:
completeSentences: [
  "Welcome to the event.",
  "Please take your seats.",
  "Thank you."
]

Input: "à¤¸à¥à¤µà¤¾à¤—à¤¤ à¤¹à¥ˆà¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¥ˆà¤ à¥‡à¤‚à¥¤" (Hindi)

Output:
completeSentences: [
  "à¤¸à¥à¤µà¤¾à¤—à¤¤ à¤¹à¥ˆà¥¤",  // Detected danda (à¥¤)
  "à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¥ˆà¤ à¥‡à¤‚à¥¤"
]
```

---

## ğŸ‘¥ User Experience During Language Switch

### What Happens from User's Perspective

#### **Scenario: User switches from English to Spanish mid-session**

```
Timeline of Events:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[T-5s] User is speaking in English
       Transcription: "Thank you all for joining today..."
       âœ… Displayed in real-time
       âœ… Broadcasting to viewers
       âœ… Translating to Hindi, Malayalam, Tamil, Telugu

[T-2s] User realizes they need to switch to Spanish
       User opens language dropdown

[T-1s] User clicks "Spanish" in dropdown
       âš ï¸  Loading indicator appears
       âš ï¸  Transcription display shows "Switching language..."

[T+0s] LANGUAGE SWITCH INITIATED
       Backend Actions:
       1. Stop current English transcription gracefully
       2. Flush any pending translations
       3. Close Deepgram Nova-3 WebSocket
       4. Determine new provider (Nova-3 for Spanish)
       5. Initialize new Deepgram connection with es language
       6. Update both sockets with new language
       
       User Visible:
       â³ Loading spinner
       ğŸ¤ Microphone still active (audio continues)
       ğŸ“ Previous transcriptions remain visible

[T+800ms] NEW CONNECTION ESTABLISHED
          Backend: Deepgram Nova-3 WebSocket connected for Spanish
          
          User Visible:
          âœ… Loading indicator disappears
          âœ… "Ready - Spanish" indicator
          ğŸ¤ Microphone active

[T+1s] User continues speaking in Spanish
       User says: "Gracias a todos por estar aquÃ­ hoy..."
       
       âœ… Spanish transcription appears in real-time
       âœ… Broadcasting Spanish transcriptions to viewers
       âœ… Translating Spanish to Hindi, Malayalam, Tamil, Telugu

[T+5s] SEAMLESS CONTINUATION
       Everything working normally in Spanish
       No interruptions, no errors, no audio gaps
```

### Visual Indicators During Switch

```javascript
// Loading State (T+0s to T+800ms)
<div className="language-switch-overlay">
  <Loader />
  <span>Switching to Spanish...</span>
  <span className="subtitle">Audio continues recording</span>
</div>

// Ready State (T+800ms onwards)
<div className="language-indicator">
  <CheckIcon />
  <span>Spanish - Ready</span>
</div>
```

### Audio Continuity Guarantee

**Key Point:** Audio is NEVER interrupted during language switches

```javascript
// MediaRecorder continues running throughout switch
const mediaRecorder = new MediaRecorder(stream);
mediaRecorder.start(100); // Starts once, continues forever

// Even when provider changes:
// 1. Old provider disconnects
// 2. New provider connects
// 3. MediaRecorder keeps running
// 4. Audio chunks continue accumulating

// Result: Zero audio loss, complete recording
```

### Error Handling During Switch

```javascript
// If language switch fails, system automatically:
try {
  await startTranscription(); // New language
} catch (error) {
  console.error("Language switch failed:", error);
  
  // Fallback actions:
  // 1. Show error toast to user
  toast.error("Failed to switch language. Please try again.");
  
  // 2. Revert to previous language
  setSelectedLanguage(previousLanguage);
  
  // 3. Attempt reconnection with old language
  await startTranscription();
  
  // 4. If reconnection fails, stop recording gracefully
  if (!isConnected) {
    stopRecording();
    toast.error("Connection lost. Please restart recording.");
  }
}
```

---

## ğŸ“ Best Practices & Recommendations

### For Users

1. **Test Language Before Going Live**
   - Use "Sound Check" feature to verify transcription quality
   - Ensure microphone is working properly
   - Check that selected language matches speech

2. **Minimize Language Switches**
   - Plan language usage before session
   - Switching takes 1-2 seconds - avoid rapid changes
   - Inform viewers before switching

3. **Stable Internet Connection**
   - 5+ Mbps upload speed recommended
   - Wired connection preferred over WiFi
   - Close bandwidth-heavy applications

4. **Clear Audio Environment**
   - Minimize background noise
   - Use quality microphone
   - Speak clearly and at moderate pace

### For Developers

1. **Provider Selection**
   - Always check `isLanguageSupported()` before starting
   - Prefer Nova when available (better quality)
   - Fallback to Speechmatics for rare languages

2. **Error Handling**
   - Implement retry logic for connection failures
   - Graceful degradation on translation errors
   - Clear error messages to users

3. **Performance Optimization**
   - Buffer audio chunks efficiently
   - Debounce rapid language switches
   - Clean up resources on unmount

4. **Testing**
   - Test all supported languages
   - Test language switching scenarios
   - Test network interruption handling
   - Test simultaneous viewer connections

---

## ğŸ“ Troubleshooting

### Common Issues

1. **Language not appearing in dropdown**
   - Check `languageUtils.js` for language support
   - Verify language code is correct
   - Check if language requires special configuration

2. **Poor transcription quality**
   - Verify correct language is selected
   - Check microphone quality
   - Reduce background noise
   - Switch to better-supported language variant

3. **Language switch stuck on loading**
   - Check network connection
   - Verify API keys are correct
   - Check browser console for errors
   - Try refreshing page

4. **Translations not appearing**
   - Verify translation socket is connected
   - Check target languages are configured in settings
   - Ensure Gemini translation server is running
   - Check browser console for socket errors

---

## ğŸ¯ Summary

### Key Takeaways

âœ… **Dual Provider System**: Seamless switching between Deepgram Nova and Speechmatics based on language support  
âœ… **Dual Socket Architecture**: Separate sockets for transcription broadcasting and translation  
âœ… **Seamless Language Switching**: 1-2 second switch time with zero audio loss  
âœ… **Smart Translation**: Sentence buffering and context-aware translations  
âœ… **Real-time Broadcasting**: Unlimited viewer support with Socket.IO  
âœ… **Production Ready**: Comprehensive error handling and cleanup  

### Architecture Highlights

- **Modular Design**: Services, hooks, and utilities are independent
- **Provider Agnostic**: Easy to add new transcription providers
- **Scalable**: Socket.IO rooms support unlimited viewers
- **Resilient**: Automatic reconnection and error recovery
- **Performant**: Efficient buffering and streaming

### Future Enhancements

- [ ] Support for more transcription providers (Google Speech, Azure, etc.)
- [ ] Automatic language detection
- [ ] Speaker diarization (identify multiple speakers)
- [ ] Real-time text formatting and editing
- [ ] Downloadable transcripts with timestamps
- [ ] Translation quality feedback loop
- [ ] Offline transcription support
- [ ] Mobile app integration

---

**Document Version:** 1.0  
**Last Updated:** October 2025  
**Maintained By:** EventHex Development Team










